<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.5">
<title>yixuan_utilities.draw_utils API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>yixuan_utilities.draw_utils</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="yixuan_utilities.draw_utils.aggr_point_cloud_from_data"><code class="name flex">
<span>def <span class="ident">aggr_point_cloud_from_data</span></span>(<span>colors: numpy.ndarray,<br>depths: numpy.ndarray,<br>Ks: numpy.ndarray,<br>poses: numpy.ndarray,<br>downsample: bool = True,<br>downsample_r: float = 0.01,<br>masks: numpy.ndarray = None,<br>boundaries: Dict | None = None,<br>out_o3d: bool = True,<br>color_fmt: <a title="yixuan_utilities.draw_utils.ImgEncoding" href="#yixuan_utilities.draw_utils.ImgEncoding">ImgEncoding</a> = ImgEncoding.RGB_UINT8,<br>depth_fmt: <a title="yixuan_utilities.draw_utils.ImgEncoding" href="#yixuan_utilities.draw_utils.ImgEncoding">ImgEncoding</a> = ImgEncoding.DEPTH_FLOAT,<br>pose_fmt: <a title="yixuan_utilities.draw_utils.ExtriConvention" href="#yixuan_utilities.draw_utils.ExtriConvention">ExtriConvention</a> = ExtriConvention.WORLD_IN_CAM) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggr_point_cloud_from_data(
    colors: np.ndarray,
    depths: np.ndarray,
    Ks: np.ndarray,
    poses: np.ndarray,
    downsample: bool = True,
    downsample_r: float = 0.01,
    masks: np.ndarray = None,
    boundaries: Optional[Dict] = None,
    out_o3d: bool = True,
    #    excluded_pts=None,
    #    exclude_threshold=0.01,):
    color_fmt: ImgEncoding = ImgEncoding.RGB_UINT8,
    depth_fmt: ImgEncoding = ImgEncoding.DEPTH_FLOAT,
    pose_fmt: ExtriConvention = ExtriConvention.WORLD_IN_CAM,
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;Aggregate point cloud from multi-view RGBD obs&#34;&#34;&#34;
    # colors: [N, H, W, 3] numpy array in uint8
    # depths: [N, H, W] numpy array in meters
    # Ks: [N, 3, 3] numpy array
    # poses: [N, 4, 4] numpy array
    # masks: [N, H, W] numpy array in bool
    N, H, W, _ = colors.shape
    if color_fmt == ImgEncoding.RGB_UINT8:
        colors = colors / 255.0
    elif color_fmt == ImgEncoding.BGR_UINT8:
        colors = colors[..., ::-1] / 255.0
    if depth_fmt == ImgEncoding.DEPTH_UINT16:
        depths = depths / 1000.0
    start = 0
    end = N
    step = 1
    pcds_ls = []
    pcd_colors = []
    # TODO: batch it
    for i in range(start, end, step):
        depth = depths[i]
        color = colors[i]
        K = Ks[i]
        cam_param = [K[0, 0], K[1, 1], K[0, 2], K[1, 2]]  # fx, fy, cx, cy
        if masks is None:
            mask = depth &gt; 0
        else:
            mask = masks[i] &amp; (depth &gt; 0)
        # mask = np.ones_like(depth, dtype=bool)

        pcd = depth2fgpcd(depth, mask, cam_param)

        pose = poses[i]
        if pose_fmt == ExtriConvention.WORLD_IN_CAM:
            try:
                pose = np.linalg.inv(pose)
            except np.linalg.LinAlgError:
                print(&#34;singular matrix&#34;)
                pose = np.linalg.pinv(pose)

        trans_pcd = pose @ np.concatenate([pcd.T, np.ones((1, pcd.shape[0]))], axis=0)
        trans_pcd = trans_pcd[:3, :].T

        color = color[mask]

        pcds_ls.append(trans_pcd)
        pcd_colors.append(color)

    pcds = np.concatenate(pcds_ls, axis=0)
    pcd_colors = np.concatenate(pcd_colors, axis=0)

    # post process 1: remove points outside of boundaries
    if boundaries is not None:
        x_lower = boundaries[&#34;x_lower&#34;]
        x_upper = boundaries[&#34;x_upper&#34;]
        y_lower = boundaries[&#34;y_lower&#34;]
        y_upper = boundaries[&#34;y_upper&#34;]
        z_lower = boundaries[&#34;z_lower&#34;]
        z_upper = boundaries[&#34;z_upper&#34;]

        pcd_mask = (
            (pcds[:, 0] &gt; x_lower)
            &amp; (pcds[:, 0] &lt; x_upper)
            &amp; (pcds[:, 1] &gt; y_lower)
            &amp; (pcds[:, 1] &lt; y_upper)
            &amp; (pcds[:, 2] &gt; z_lower)
            &amp; (pcds[:, 2] &lt; z_upper)
        )

        pcds = pcds[pcd_mask]
        pcd_colors = pcd_colors[pcd_mask]

    # post process 2: downsample
    if downsample:
        pcds, pcd_colors = voxel_downsample_numpy(pcds, downsample_r, pcd_colors)

    # post process 3: return o3d point cloud if out_o3d is True
    if out_o3d:
        aggr_pcd = np2o3d(pcds, pcd_colors)
        return aggr_pcd
    else:
        return pcds, pcd_colors</code></pre>
</details>
<div class="desc"><p>Aggregate point cloud from multi-view RGBD obs</p></div>
</dd>
<dt id="yixuan_utilities.draw_utils.aggr_point_cloud_tensor"><code class="name flex">
<span>def <span class="ident">aggr_point_cloud_tensor</span></span>(<span>colors: numpy.ndarray,<br>depths: numpy.ndarray,<br>Ks: numpy.ndarray,<br>poses: numpy.ndarray,<br>masks: numpy.ndarray = None,<br>downsample: bool = True,<br>downsample_r: float = 0.01,<br>boundaries: Dict | None = None,<br>color_fmt: <a title="yixuan_utilities.draw_utils.ImgEncoding" href="#yixuan_utilities.draw_utils.ImgEncoding">ImgEncoding</a> = ImgEncoding.RGB_UINT8,<br>depth_fmt: <a title="yixuan_utilities.draw_utils.ImgEncoding" href="#yixuan_utilities.draw_utils.ImgEncoding">ImgEncoding</a> = ImgEncoding.DEPTH_FLOAT,<br>pose_fmt: <a title="yixuan_utilities.draw_utils.ExtriConvention" href="#yixuan_utilities.draw_utils.ExtriConvention">ExtriConvention</a> = ExtriConvention.WORLD_IN_CAM) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggr_point_cloud_tensor(
    colors: np.ndarray,
    depths: np.ndarray,
    Ks: np.ndarray,
    poses: np.ndarray,
    masks: np.ndarray = None,
    downsample: bool = True,
    downsample_r: float = 0.01,
    boundaries: Optional[Dict] = None,
    color_fmt: ImgEncoding = ImgEncoding.RGB_UINT8,
    depth_fmt: ImgEncoding = ImgEncoding.DEPTH_FLOAT,
    pose_fmt: ExtriConvention = ExtriConvention.WORLD_IN_CAM,
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;Aggregate point cloud from multi-view RGBD obs&#34;&#34;&#34;
    # colors: [N, H, W, 3] numpy array in uint8
    # depths: [N, H, W] numpy array in meters
    # Ks: [N, 3, 3] numpy array
    # poses: [N, 4, 4] numpy array
    N, H, W, _ = colors.shape
    if color_fmt == ImgEncoding.RGB_UINT8:
        colors = colors / 255.0
    elif color_fmt == ImgEncoding.BGR_UINT8:
        colors = colors[..., ::-1] / 255.0
    if depth_fmt == ImgEncoding.DEPTH_UINT16:
        depths = depths / 1000.0

    # convert to torch tensor
    device = &#34;cuda&#34;
    colors_tensor = torch.from_numpy(colors).to(dtype=torch.float32, device=device)
    depths_tensor = torch.from_numpy(depths).to(dtype=torch.float32, device=device)
    masks_tensor = torch.from_numpy(masks).to(dtype=torch.bool, device=device)
    Ks_tensor = torch.from_numpy(Ks).to(dtype=torch.float32, device=device)
    poses_tensor = torch.from_numpy(poses).to(dtype=torch.float32, device=device)

    # map to camera frame
    pcd_tensor = torch.zeros((N, H, W, 3), dtype=torch.float32, device=device)
    pos_y, pos_x = torch.meshgrid([torch.arange(H), torch.arange(W)])  # (H, W), (H, W)
    pos_y = pos_y.to(device)
    pos_x = pos_x.to(device)
    pos_x = torch.tile(pos_x[None], (N, 1, 1))  # [N, H, W]
    pos_y = torch.tile(pos_y[None], (N, 1, 1))  # [N, H, W]
    pcd_tensor[..., 0] = (
        (pos_x - Ks_tensor[:, 0:1, 2:3]) * depths_tensor / Ks_tensor[:, 0:1, 0:1]
    )
    pcd_tensor[..., 1] = (
        (pos_y - Ks_tensor[:, 1:2, 2:3]) * depths_tensor / Ks_tensor[:, 1:2, 1:2]
    )
    pcd_tensor[..., 2] = depths_tensor

    # map to world frame
    pcd_tensor = pcd_tensor.reshape(N, H * W, 3)
    pcd_tensor = torch.cat(
        [pcd_tensor, torch.ones((N, H * W, 1), dtype=torch.float32, device=device)],
        dim=-1,
    )  # (N, H*W, 4)
    if pose_fmt == ExtriConvention.WORLD_IN_CAM:
        try:
            poses_tensor = torch.linalg.inv(poses_tensor)
        except torch.linalg.LinAlgError:
            poses_tensor = torch.linalg.pinv(poses_tensor)
    pcd_tensor = torch.bmm(poses_tensor, pcd_tensor.permute(0, 2, 1))  # (N, 4, H*W)
    pcd_tensor = pcd_tensor[:, :3].permute(0, 2, 1).reshape(N, H, W, 3)

    # post process 1: mask out
    pcd_tensor = pcd_tensor[masks_tensor]  # [M, 3]
    pcd_colors = colors_tensor[masks_tensor]  # [M, 3]

    # post process 2: remove points outside of boundaries
    if boundaries is not None:
        x_lower = boundaries[&#34;x_lower&#34;]
        x_upper = boundaries[&#34;x_upper&#34;]
        y_lower = boundaries[&#34;y_lower&#34;]
        y_upper = boundaries[&#34;y_upper&#34;]
        z_lower = boundaries[&#34;z_lower&#34;]
        z_upper = boundaries[&#34;z_upper&#34;]

        pcd_mask = (
            (pcd_tensor[:, 0] &gt; x_lower)
            &amp; (pcd_tensor[:, 0] &lt; x_upper)
            &amp; (pcd_tensor[:, 1] &gt; y_lower)
            &amp; (pcd_tensor[:, 1] &lt; y_upper)
            &amp; (pcd_tensor[:, 2] &gt; z_lower)
            &amp; (pcd_tensor[:, 2] &lt; z_upper)
        )

        pcd_tensor = pcd_tensor[pcd_mask]
        pcd_colors = pcd_colors[pcd_mask]

    # post process 3: downsample
    if downsample:
        pcd_tensor, pcd_colors = voxel_downsample_torch(
            pcd_tensor, downsample_r, pcd_colors
        )

    return pcd_tensor.cpu().numpy(), pcd_colors.cpu().numpy()</code></pre>
</details>
<div class="desc"><p>Aggregate point cloud from multi-view RGBD obs</p></div>
</dd>
<dt id="yixuan_utilities.draw_utils.center_crop"><code class="name flex">
<span>def <span class="ident">center_crop</span></span>(<span>img: numpy.ndarray, crop_size: tuple[int, int]) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def center_crop(img: np.ndarray, crop_size: tuple[int, int]) -&gt; np.ndarray:
    h, w = img.shape[:2]
    th, tw = crop_size
    if h / w &gt; th / tw:
        # image is taller than crop
        crop_w = w
        crop_h = int(round(w * th / tw))
    elif h / w &lt; th / tw:
        # image is wider than crop
        crop_h = h
        crop_w = int(round(h * tw / th))
    else:
        return img
    x1 = (w - crop_w) // 2
    y1 = (h - crop_h) // 2
    return img[y1 : y1 + crop_h, x1 : x1 + crop_w]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="yixuan_utilities.draw_utils.depth2fgpcd"><code class="name flex">
<span>def <span class="ident">depth2fgpcd</span></span>(<span>depth: numpy.ndarray,<br>mask: numpy.ndarray,<br>cam_params: List,<br>preserve_zero: bool = False) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def depth2fgpcd(
    depth: np.ndarray, mask: np.ndarray, cam_params: List, preserve_zero: bool = False
) -&gt; np.ndarray:
    &#34;&#34;&#34;Convert depth image to foreground point cloud&#34;&#34;&#34;
    # depth: (h, w)
    # fgpcd: (n, 3)
    # mask: (h, w)
    h, w = depth.shape
    if not preserve_zero:
        mask = np.logical_and(mask, depth &gt; 0)
    fgpcd = np.zeros((mask.sum(), 3))
    fx, fy, cx, cy = cam_params
    pos_x, pos_y = np.meshgrid(np.arange(w), np.arange(h))
    pos_x = pos_x[mask]
    pos_y = pos_y[mask]
    fgpcd[:, 0] = (pos_x - cx) * depth[mask] / fx
    fgpcd[:, 1] = (pos_y - cy) * depth[mask] / fy
    fgpcd[:, 2] = depth[mask]
    return fgpcd</code></pre>
</details>
<div class="desc"><p>Convert depth image to foreground point cloud</p></div>
</dd>
<dt id="yixuan_utilities.draw_utils.depth2fgpcd_tensor"><code class="name flex">
<span>def <span class="ident">depth2fgpcd_tensor</span></span>(<span>depth: torch.Tensor, cam_params: torch.Tensor) ‑> torch.Tensor</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def depth2fgpcd_tensor(depth: torch.Tensor, cam_params: torch.Tensor) -&gt; torch.Tensor:
    &#34;&#34;&#34;Convert depth image to foreground point cloud using PyTorch tensors.

    Args:
    depth (torch.Tensor): Depth image tensor of shape (b, h, w).
    cam_params (torch.Tensor): Camera parameters tensor of shape (b, 4).

    Returns:
    torch.Tensor: Foreground point cloud tensor of shape (b, h*w, 3).
    &#34;&#34;&#34;
    b, h, w = depth.shape

    pos_x, pos_y = torch.meshgrid(
        torch.arange(w, device=depth.device),
        torch.arange(h, device=depth.device),
        indexing=&#34;xy&#34;,
    )
    pos_x = pos_x.unsqueeze(0).expand(b, -1, -1).reshape(b, h * w)
    pos_y = pos_y.unsqueeze(0).expand(b, -1, -1).reshape(b, h * w)

    cam_params = cam_params.unsqueeze(-1).unsqueeze(
        -1
    )  # Expand cam_params to match the shape of pos_x and pos_y

    fx = cam_params[:, 0]
    fy = cam_params[:, 1]
    cx = cam_params[:, 2]
    cy = cam_params[:, 3]

    fgpcd = torch.zeros((b, h * w, 3), device=depth.device, dtype=torch.float32)
    fgpcd[..., 0] = (pos_x - cx) * depth.reshape(b, h * w) / fx
    fgpcd[..., 1] = (pos_y - cy) * depth.reshape(b, h * w) / fy
    fgpcd[..., 2] = depth.reshape(b, h * w)

    return fgpcd</code></pre>
</details>
<div class="desc"><p>Convert depth image to foreground point cloud using PyTorch tensors.</p>
<p>Args:
depth (torch.Tensor): Depth image tensor of shape (b, h, w).
cam_params (torch.Tensor): Camera parameters tensor of shape (b, 4).</p>
<p>Returns:
torch.Tensor: Foreground point cloud tensor of shape (b, h*w, 3).</p></div>
</dd>
<dt id="yixuan_utilities.draw_utils.np2o3d"><code class="name flex">
<span>def <span class="ident">np2o3d</span></span>(<span>pcd: numpy.ndarray, color: numpy.ndarray | None = None) ‑> open3d.cpu.pybind.geometry.PointCloud</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def np2o3d(
    pcd: np.ndarray, color: Union[None, np.ndarray] = None
) -&gt; o3d.geometry.PointCloud:
    # pcd: (n, 3)
    # color: (n, 3)
    pcd_o3d = o3d.geometry.PointCloud()
    pcd_o3d.points = o3d.utility.Vector3dVector(pcd)
    if color is not None:
        assert pcd.shape[0] == color.shape[0]
        assert color.max() &lt;= 1
        assert color.min() &gt;= 0
        pcd_o3d.colors = o3d.utility.Vector3dVector(color)
    return pcd_o3d</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="yixuan_utilities.draw_utils.resize_to_height"><code class="name flex">
<span>def <span class="ident">resize_to_height</span></span>(<span>img: numpy.ndarray, height: int) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resize_to_height(img: np.ndarray, height: int) -&gt; np.ndarray:
    h, w = img.shape[:2]
    scale = height / h
    return cv2.resize(img, (int(w * scale), height), interpolation=cv2.INTER_LINEAR)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="yixuan_utilities.draw_utils.test_o3d_vis"><code class="name flex">
<span>def <span class="ident">test_o3d_vis</span></span>(<span>) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_o3d_vis() -&gt; None:
    view_ctrl_info = {
        &#34;front&#34;: [0.36137433126422974, 0.5811161319788094, 0.72918628200022917],
        &#34;lookat&#34;: [0.45000000000000001, 0.45000000000000001, 0.45000000000000001],
        &#34;up&#34;: [-0.17552920841503886, 0.81045157347999874, -0.55888974229000143],
        &#34;zoom&#34;: 1.3400000000000005,
    }
    o3d_vis = o3dVisualizer(view_ctrl_info=view_ctrl_info, save_path=&#34;tmp&#34;)
    o3d_vis.start()
    for i in range(100):
        rand_pcd_np = np.random.rand(100, 3)
        rand_pcd_colors = np.random.rand(100, 3)
        rand_pcd_o3d = np2o3d(rand_pcd_np, rand_pcd_colors)
        o3d_vis.update_pcd(rand_pcd_o3d, &#34;rand_pcd&#34;)
        if i == 0:
            o3d_vis.add_triangle_mesh(
                &#34;sphere&#34;, &#34;sphere&#34;, color=[1.0, 0.0, 0.0], radius=0.1
            )
            o3d_vis.add_triangle_mesh(
                &#34;box&#34;, &#34;box&#34;, color=[0.0, 1.0, 0.0], width=0.1, height=0.1, depth=0.1
            )
            o3d_vis.add_triangle_mesh(&#34;origin&#34;, &#34;origin&#34;, size=1.0)
        else:
            sphere_tf = np.eye(4)
            sphere_tf[0, 3] = 0.01 * i
            o3d_vis.update_triangle_mesh(&#34;sphere&#34;, sphere_tf)

            box_tf = np.eye(4)
            box_tf[1, 3] = -0.01 * i
            o3d_vis.update_triangle_mesh(&#34;box&#34;, box_tf)
        o3d_vis.render(curr_view_ctrl_info=view_ctrl_info)
        time.sleep(0.1)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="yixuan_utilities.draw_utils.voxel_downsample_numpy"><code class="name flex">
<span>def <span class="ident">voxel_downsample_numpy</span></span>(<span>points: numpy.ndarray,<br>voxel_size: float,<br>points_color: numpy.ndarray | None = None) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def voxel_downsample_numpy(
    points: np.ndarray, voxel_size: float, points_color: Optional[np.ndarray] = None
) -&gt; Tuple[np.ndarray, np.ndarray]:
    # Ensure the points array is in float format for division
    points = points.astype(np.float32)

    # Compute voxel indices
    voxel_indices = np.floor(points / voxel_size)

    # Create a unique index for each voxel using its 3D index
    unique_voxels, indices = np.unique(voxel_indices, return_inverse=True, axis=0)

    # Initialize voxel_points to store the sum of points in each voxel
    voxel_points = np.zeros((unique_voxels.shape[0], points.shape[1]), dtype=np.float32)

    # Sum points in each voxel
    np.add.at(voxel_points, indices, points)

    # Count the number of points in each voxel
    counts = np.zeros((unique_voxels.shape[0], 1), dtype=np.float32)
    np.add.at(counts, indices, 1)

    # Calculate the centroid
    centroids = voxel_points / counts
    if points_color is not None:
        points_color = points_color.astype(np.float32)
        voxel_colors = np.zeros(
            (unique_voxels.shape[0], points_color.shape[1]), dtype=np.float32
        )
        np.add.at(voxel_colors, indices, points_color)
        centroids_color = voxel_colors / counts
    else:
        centroids_color = np.array([])

    return centroids, centroids_color</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="yixuan_utilities.draw_utils.voxel_downsample_torch"><code class="name flex">
<span>def <span class="ident">voxel_downsample_torch</span></span>(<span>points: torch.Tensor,<br>voxel_size: float,<br>points_color: torch.Tensor | None = None) ‑> Tuple[torch.Tensor, torch.Tensor]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def voxel_downsample_torch(
    points: torch.Tensor, voxel_size: float, points_color: Optional[torch.Tensor] = None
) -&gt; Tuple[torch.Tensor, torch.Tensor]:
    # Ensure the points tensor is in float format for division
    points = points.float()

    # Compute voxel indices
    voxel_indices = (points / voxel_size).floor()

    # Create a unique index for each voxel using its 3D index
    unique_voxels, indices = torch.unique(voxel_indices, return_inverse=True, dim=0)

    # Initialize voxel_points to store the sum of points in each voxel
    voxel_points = torch.zeros(
        unique_voxels.size(0), points.size(1), dtype=torch.float, device=points.device
    )

    # Sum points in each voxel
    voxel_points.index_add_(0, indices, points)

    # Count the number of points in each voxel
    counts = torch.zeros(
        unique_voxels.size(0), 1, dtype=torch.float, device=points.device
    )
    counts.index_add_(0, indices, torch.ones(points.size(0), 1, device=points.device))

    # Calculate the centroid
    centroids = voxel_points / counts
    if points_color is not None:
        points_color = points_color.float()
        voxel_colors = torch.zeros(
            unique_voxels.size(0),
            points_color.size(1),
            dtype=torch.float,
            device=points.device,
        )
        voxel_colors.index_add_(0, indices, points_color)
        centroids_color = voxel_colors / counts
    else:
        centroids_color = torch.Tensor()

    return centroids, centroids_color</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="yixuan_utilities.draw_utils.ExtriConvention"><code class="flex name class">
<span>class <span class="ident">ExtriConvention</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ExtriConvention(Enum):
    &#34;&#34;&#34;Extrinsic convention for camera pose&#34;&#34;&#34;

    CAM_IN_WORLD = &#34;cam_in_world&#34;  # camera pose in world coord
    WORLD_IN_CAM = &#34;world_in_cam&#34;  # world pose in camera coord</code></pre>
</details>
<div class="desc"><p>Extrinsic convention for camera pose</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="yixuan_utilities.draw_utils.ExtriConvention.CAM_IN_WORLD"><code class="name">var <span class="ident">CAM_IN_WORLD</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="yixuan_utilities.draw_utils.ExtriConvention.WORLD_IN_CAM"><code class="name">var <span class="ident">WORLD_IN_CAM</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="yixuan_utilities.draw_utils.ImgEncoding"><code class="flex name class">
<span>class <span class="ident">ImgEncoding</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ImgEncoding(Enum):
    &#34;&#34;&#34;Image encoding format&#34;&#34;&#34;

    RGB_UINT8 = &#34;rgb_uint8&#34;
    BGR_UINT8 = &#34;bgr_uint8&#34;
    DEPTH_UINT16 = &#34;depth_uint16&#34;
    DEPTH_FLOAT = &#34;depth_float&#34;</code></pre>
</details>
<div class="desc"><p>Image encoding format</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="yixuan_utilities.draw_utils.ImgEncoding.BGR_UINT8"><code class="name">var <span class="ident">BGR_UINT8</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="yixuan_utilities.draw_utils.ImgEncoding.DEPTH_FLOAT"><code class="name">var <span class="ident">DEPTH_FLOAT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="yixuan_utilities.draw_utils.ImgEncoding.DEPTH_UINT16"><code class="name">var <span class="ident">DEPTH_UINT16</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="yixuan_utilities.draw_utils.ImgEncoding.RGB_UINT8"><code class="name">var <span class="ident">RGB_UINT8</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="yixuan_utilities.draw_utils.o3dVisualizer"><code class="flex name class">
<span>class <span class="ident">o3dVisualizer</span></span>
<span>(</span><span>view_ctrl_info: Dict | None = None, save_path: str | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class o3dVisualizer:
    &#34;&#34;&#34;open3d visualizer&#34;&#34;&#34;

    def __init__(
        self, view_ctrl_info: Optional[Dict] = None, save_path: Optional[str] = None
    ) -&gt; None:
        &#34;&#34;&#34;initialize o3d visualizer

        Args:
            view_ctrl_info (dict): view control info containing front, lookat, up, zoom
            save_path (_type_, optional): _description_. Defaults to None.
        &#34;&#34;&#34;
        self.view_ctrl_info = view_ctrl_info
        self.save_path = save_path
        self.visualizer = o3d.visualization.Visualizer()
        self.vis_dict: Dict[str, o3d.geometry.PointCloud] = {}
        self.mesh_vertices: Dict[str, np.ndarray] = {}
        self.is_first = True
        self.internal_clock = 0
        if save_path is not None:
            os.system(f&#34;mkdir -p {save_path}&#34;)

    def start(self) -&gt; None:
        &#34;&#34;&#34;start the visualizer&#34;&#34;&#34;
        self.visualizer.create_window()

    def update_pcd(self, mesh: o3d.geometry.PointCloud, mesh_name: str) -&gt; None:
        &#34;&#34;&#34;update point cloud&#34;&#34;&#34;
        if mesh_name not in self.vis_dict.keys():
            self.vis_dict[mesh_name] = o3d.geometry.PointCloud()
            self.vis_dict[mesh_name].points = mesh.points
            self.vis_dict[mesh_name].colors = mesh.colors
            self.visualizer.add_geometry(self.vis_dict[mesh_name])
        else:
            self.vis_dict[mesh_name].points = mesh.points
            self.vis_dict[mesh_name].colors = mesh.colors

    def add_triangle_mesh(
        self,
        type: str,
        mesh_name: str,
        color: Optional[np.ndarray] = None,
        radius: float = 0.1,
        width: float = 0.1,
        height: float = 0.1,
        depth: float = 0.1,
        size: float = 0.1,
    ) -&gt; None:
        &#34;&#34;&#34;add triangle mesh to the visualizer&#34;&#34;&#34;
        if type == &#34;sphere&#34;:
            mesh = o3d.geometry.TriangleMesh.create_sphere(radius=radius)
        elif type == &#34;box&#34;:
            mesh = o3d.geometry.TriangleMesh.create_box(
                width=width, height=height, depth=depth
            )
        elif type == &#34;origin&#34;:
            mesh = o3d.geometry.TriangleMesh.create_coordinate_frame(size=size)
        else:
            raise NotImplementedError
        if color is not None:
            mesh.paint_uniform_color(color)
        self.vis_dict[mesh_name] = mesh
        self.mesh_vertices[mesh_name] = np.array(mesh.vertices).copy()
        self.visualizer.add_geometry(self.vis_dict[mesh_name])

    def update_triangle_mesh(self, mesh_name: str, tf: np.ndarray) -&gt; None:
        &#34;&#34;&#34;update triangle mesh&#34;&#34;&#34;
        tf_vertices = self.mesh_vertices[mesh_name] @ tf[:3, :3].T + tf[:3, 3]
        self.vis_dict[mesh_name].vertices = o3d.utility.Vector3dVector(tf_vertices)

    def update_custom_mesh(
        self, mesh: o3d.geometry.TriangleMesh, mesh_name: str
    ) -&gt; None:
        &#34;&#34;&#34;update custom mesh&#34;&#34;&#34;
        if mesh_name not in self.vis_dict.keys():
            self.vis_dict[mesh_name] = copy.deepcopy(mesh)
            self.visualizer.add_geometry(self.vis_dict[mesh_name])
        else:
            self.visualizer.remove_geometry(self.vis_dict[mesh_name], False)
            del self.vis_dict[mesh_name]
            self.vis_dict[mesh_name] = copy.deepcopy(mesh)
            self.visualizer.add_geometry(self.vis_dict[mesh_name])
        self.visualizer.update_geometry(self.vis_dict[mesh_name])
        self.mesh_vertices[mesh_name] = np.array(mesh.vertices).copy()

    def render(
        self,
        render_names: Optional[List[str]] = None,
        save_name: Optional[str] = None,
        curr_view_ctrl_info: Optional[Dict] = None,
    ) -&gt; np.ndarray:
        &#34;&#34;&#34;render the scene&#34;&#34;&#34;
        if self.view_ctrl_info is not None and curr_view_ctrl_info is None:
            view_control = self.visualizer.get_view_control()
            view_control.set_front(self.view_ctrl_info[&#34;front&#34;])
            view_control.set_lookat(self.view_ctrl_info[&#34;lookat&#34;])
            view_control.set_up(self.view_ctrl_info[&#34;up&#34;])
            view_control.set_zoom(self.view_ctrl_info[&#34;zoom&#34;])
        elif curr_view_ctrl_info is not None:
            view_control = self.visualizer.get_view_control()
            view_control.set_front(curr_view_ctrl_info[&#34;front&#34;])
            view_control.set_lookat(curr_view_ctrl_info[&#34;lookat&#34;])
            view_control.set_up(curr_view_ctrl_info[&#34;up&#34;])
            view_control.set_zoom(curr_view_ctrl_info[&#34;zoom&#34;])
        if render_names is None:
            for mesh_name in self.vis_dict.keys():
                self.visualizer.update_geometry(self.vis_dict[mesh_name])
        else:
            for mesh_name in self.vis_dict.keys():
                if mesh_name in render_names:
                    self.visualizer.update_geometry(self.vis_dict[mesh_name])
                else:
                    self.visualizer.remove_geometry(self.vis_dict[mesh_name], False)
        self.visualizer.poll_events()
        self.visualizer.update_renderer()
        # self.visualizer.run()

        img = None
        if self.save_path is not None:
            if save_name is None:
                save_fn = f&#34;{self.save_path}/{self.internal_clock}.png&#34;
            else:
                save_fn = f&#34;{self.save_path}/{save_name}.png&#34;
            self.visualizer.capture_screen_image(save_fn)
            img = cv2.imread(save_fn)
            self.internal_clock += 1

        # add back
        if render_names is not None:
            for mesh_name in self.vis_dict.keys():
                if mesh_name not in render_names:
                    self.visualizer.add_geometry(self.vis_dict[mesh_name])

        return img

    def close(self) -&gt; None:
        &#34;&#34;&#34;close the visualizer&#34;&#34;&#34;
        self.visualizer.destroy_window()</code></pre>
</details>
<div class="desc"><p>open3d visualizer</p>
<p>initialize o3d visualizer</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>view_ctrl_info</code></strong> :&ensp;<code>dict</code></dt>
<dd>view control info containing front, lookat, up, zoom</dd>
<dt><strong><code>save_path</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd><em>description</em>. Defaults to None.</dd>
</dl></div>
<h3>Methods</h3>
<dl>
<dt id="yixuan_utilities.draw_utils.o3dVisualizer.add_triangle_mesh"><code class="name flex">
<span>def <span class="ident">add_triangle_mesh</span></span>(<span>self,<br>type: str,<br>mesh_name: str,<br>color: numpy.ndarray | None = None,<br>radius: float = 0.1,<br>width: float = 0.1,<br>height: float = 0.1,<br>depth: float = 0.1,<br>size: float = 0.1) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_triangle_mesh(
    self,
    type: str,
    mesh_name: str,
    color: Optional[np.ndarray] = None,
    radius: float = 0.1,
    width: float = 0.1,
    height: float = 0.1,
    depth: float = 0.1,
    size: float = 0.1,
) -&gt; None:
    &#34;&#34;&#34;add triangle mesh to the visualizer&#34;&#34;&#34;
    if type == &#34;sphere&#34;:
        mesh = o3d.geometry.TriangleMesh.create_sphere(radius=radius)
    elif type == &#34;box&#34;:
        mesh = o3d.geometry.TriangleMesh.create_box(
            width=width, height=height, depth=depth
        )
    elif type == &#34;origin&#34;:
        mesh = o3d.geometry.TriangleMesh.create_coordinate_frame(size=size)
    else:
        raise NotImplementedError
    if color is not None:
        mesh.paint_uniform_color(color)
    self.vis_dict[mesh_name] = mesh
    self.mesh_vertices[mesh_name] = np.array(mesh.vertices).copy()
    self.visualizer.add_geometry(self.vis_dict[mesh_name])</code></pre>
</details>
<div class="desc"><p>add triangle mesh to the visualizer</p></div>
</dd>
<dt id="yixuan_utilities.draw_utils.o3dVisualizer.close"><code class="name flex">
<span>def <span class="ident">close</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close(self) -&gt; None:
    &#34;&#34;&#34;close the visualizer&#34;&#34;&#34;
    self.visualizer.destroy_window()</code></pre>
</details>
<div class="desc"><p>close the visualizer</p></div>
</dd>
<dt id="yixuan_utilities.draw_utils.o3dVisualizer.render"><code class="name flex">
<span>def <span class="ident">render</span></span>(<span>self,<br>render_names: List[str] | None = None,<br>save_name: str | None = None,<br>curr_view_ctrl_info: Dict | None = None) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def render(
    self,
    render_names: Optional[List[str]] = None,
    save_name: Optional[str] = None,
    curr_view_ctrl_info: Optional[Dict] = None,
) -&gt; np.ndarray:
    &#34;&#34;&#34;render the scene&#34;&#34;&#34;
    if self.view_ctrl_info is not None and curr_view_ctrl_info is None:
        view_control = self.visualizer.get_view_control()
        view_control.set_front(self.view_ctrl_info[&#34;front&#34;])
        view_control.set_lookat(self.view_ctrl_info[&#34;lookat&#34;])
        view_control.set_up(self.view_ctrl_info[&#34;up&#34;])
        view_control.set_zoom(self.view_ctrl_info[&#34;zoom&#34;])
    elif curr_view_ctrl_info is not None:
        view_control = self.visualizer.get_view_control()
        view_control.set_front(curr_view_ctrl_info[&#34;front&#34;])
        view_control.set_lookat(curr_view_ctrl_info[&#34;lookat&#34;])
        view_control.set_up(curr_view_ctrl_info[&#34;up&#34;])
        view_control.set_zoom(curr_view_ctrl_info[&#34;zoom&#34;])
    if render_names is None:
        for mesh_name in self.vis_dict.keys():
            self.visualizer.update_geometry(self.vis_dict[mesh_name])
    else:
        for mesh_name in self.vis_dict.keys():
            if mesh_name in render_names:
                self.visualizer.update_geometry(self.vis_dict[mesh_name])
            else:
                self.visualizer.remove_geometry(self.vis_dict[mesh_name], False)
    self.visualizer.poll_events()
    self.visualizer.update_renderer()
    # self.visualizer.run()

    img = None
    if self.save_path is not None:
        if save_name is None:
            save_fn = f&#34;{self.save_path}/{self.internal_clock}.png&#34;
        else:
            save_fn = f&#34;{self.save_path}/{save_name}.png&#34;
        self.visualizer.capture_screen_image(save_fn)
        img = cv2.imread(save_fn)
        self.internal_clock += 1

    # add back
    if render_names is not None:
        for mesh_name in self.vis_dict.keys():
            if mesh_name not in render_names:
                self.visualizer.add_geometry(self.vis_dict[mesh_name])

    return img</code></pre>
</details>
<div class="desc"><p>render the scene</p></div>
</dd>
<dt id="yixuan_utilities.draw_utils.o3dVisualizer.start"><code class="name flex">
<span>def <span class="ident">start</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start(self) -&gt; None:
    &#34;&#34;&#34;start the visualizer&#34;&#34;&#34;
    self.visualizer.create_window()</code></pre>
</details>
<div class="desc"><p>start the visualizer</p></div>
</dd>
<dt id="yixuan_utilities.draw_utils.o3dVisualizer.update_custom_mesh"><code class="name flex">
<span>def <span class="ident">update_custom_mesh</span></span>(<span>self, mesh: open3d.cpu.pybind.geometry.TriangleMesh, mesh_name: str) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_custom_mesh(
    self, mesh: o3d.geometry.TriangleMesh, mesh_name: str
) -&gt; None:
    &#34;&#34;&#34;update custom mesh&#34;&#34;&#34;
    if mesh_name not in self.vis_dict.keys():
        self.vis_dict[mesh_name] = copy.deepcopy(mesh)
        self.visualizer.add_geometry(self.vis_dict[mesh_name])
    else:
        self.visualizer.remove_geometry(self.vis_dict[mesh_name], False)
        del self.vis_dict[mesh_name]
        self.vis_dict[mesh_name] = copy.deepcopy(mesh)
        self.visualizer.add_geometry(self.vis_dict[mesh_name])
    self.visualizer.update_geometry(self.vis_dict[mesh_name])
    self.mesh_vertices[mesh_name] = np.array(mesh.vertices).copy()</code></pre>
</details>
<div class="desc"><p>update custom mesh</p></div>
</dd>
<dt id="yixuan_utilities.draw_utils.o3dVisualizer.update_pcd"><code class="name flex">
<span>def <span class="ident">update_pcd</span></span>(<span>self, mesh: open3d.cpu.pybind.geometry.PointCloud, mesh_name: str) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_pcd(self, mesh: o3d.geometry.PointCloud, mesh_name: str) -&gt; None:
    &#34;&#34;&#34;update point cloud&#34;&#34;&#34;
    if mesh_name not in self.vis_dict.keys():
        self.vis_dict[mesh_name] = o3d.geometry.PointCloud()
        self.vis_dict[mesh_name].points = mesh.points
        self.vis_dict[mesh_name].colors = mesh.colors
        self.visualizer.add_geometry(self.vis_dict[mesh_name])
    else:
        self.vis_dict[mesh_name].points = mesh.points
        self.vis_dict[mesh_name].colors = mesh.colors</code></pre>
</details>
<div class="desc"><p>update point cloud</p></div>
</dd>
<dt id="yixuan_utilities.draw_utils.o3dVisualizer.update_triangle_mesh"><code class="name flex">
<span>def <span class="ident">update_triangle_mesh</span></span>(<span>self, mesh_name: str, tf: numpy.ndarray) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_triangle_mesh(self, mesh_name: str, tf: np.ndarray) -&gt; None:
    &#34;&#34;&#34;update triangle mesh&#34;&#34;&#34;
    tf_vertices = self.mesh_vertices[mesh_name] @ tf[:3, :3].T + tf[:3, 3]
    self.vis_dict[mesh_name].vertices = o3d.utility.Vector3dVector(tf_vertices)</code></pre>
</details>
<div class="desc"><p>update triangle mesh</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="yixuan_utilities" href="index.html">yixuan_utilities</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="yixuan_utilities.draw_utils.aggr_point_cloud_from_data" href="#yixuan_utilities.draw_utils.aggr_point_cloud_from_data">aggr_point_cloud_from_data</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.aggr_point_cloud_tensor" href="#yixuan_utilities.draw_utils.aggr_point_cloud_tensor">aggr_point_cloud_tensor</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.center_crop" href="#yixuan_utilities.draw_utils.center_crop">center_crop</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.depth2fgpcd" href="#yixuan_utilities.draw_utils.depth2fgpcd">depth2fgpcd</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.depth2fgpcd_tensor" href="#yixuan_utilities.draw_utils.depth2fgpcd_tensor">depth2fgpcd_tensor</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.np2o3d" href="#yixuan_utilities.draw_utils.np2o3d">np2o3d</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.resize_to_height" href="#yixuan_utilities.draw_utils.resize_to_height">resize_to_height</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.test_o3d_vis" href="#yixuan_utilities.draw_utils.test_o3d_vis">test_o3d_vis</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.voxel_downsample_numpy" href="#yixuan_utilities.draw_utils.voxel_downsample_numpy">voxel_downsample_numpy</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.voxel_downsample_torch" href="#yixuan_utilities.draw_utils.voxel_downsample_torch">voxel_downsample_torch</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="yixuan_utilities.draw_utils.ExtriConvention" href="#yixuan_utilities.draw_utils.ExtriConvention">ExtriConvention</a></code></h4>
<ul class="">
<li><code><a title="yixuan_utilities.draw_utils.ExtriConvention.CAM_IN_WORLD" href="#yixuan_utilities.draw_utils.ExtriConvention.CAM_IN_WORLD">CAM_IN_WORLD</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.ExtriConvention.WORLD_IN_CAM" href="#yixuan_utilities.draw_utils.ExtriConvention.WORLD_IN_CAM">WORLD_IN_CAM</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="yixuan_utilities.draw_utils.ImgEncoding" href="#yixuan_utilities.draw_utils.ImgEncoding">ImgEncoding</a></code></h4>
<ul class="">
<li><code><a title="yixuan_utilities.draw_utils.ImgEncoding.BGR_UINT8" href="#yixuan_utilities.draw_utils.ImgEncoding.BGR_UINT8">BGR_UINT8</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.ImgEncoding.DEPTH_FLOAT" href="#yixuan_utilities.draw_utils.ImgEncoding.DEPTH_FLOAT">DEPTH_FLOAT</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.ImgEncoding.DEPTH_UINT16" href="#yixuan_utilities.draw_utils.ImgEncoding.DEPTH_UINT16">DEPTH_UINT16</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.ImgEncoding.RGB_UINT8" href="#yixuan_utilities.draw_utils.ImgEncoding.RGB_UINT8">RGB_UINT8</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="yixuan_utilities.draw_utils.o3dVisualizer" href="#yixuan_utilities.draw_utils.o3dVisualizer">o3dVisualizer</a></code></h4>
<ul class="">
<li><code><a title="yixuan_utilities.draw_utils.o3dVisualizer.add_triangle_mesh" href="#yixuan_utilities.draw_utils.o3dVisualizer.add_triangle_mesh">add_triangle_mesh</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.o3dVisualizer.close" href="#yixuan_utilities.draw_utils.o3dVisualizer.close">close</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.o3dVisualizer.render" href="#yixuan_utilities.draw_utils.o3dVisualizer.render">render</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.o3dVisualizer.start" href="#yixuan_utilities.draw_utils.o3dVisualizer.start">start</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.o3dVisualizer.update_custom_mesh" href="#yixuan_utilities.draw_utils.o3dVisualizer.update_custom_mesh">update_custom_mesh</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.o3dVisualizer.update_pcd" href="#yixuan_utilities.draw_utils.o3dVisualizer.update_pcd">update_pcd</a></code></li>
<li><code><a title="yixuan_utilities.draw_utils.o3dVisualizer.update_triangle_mesh" href="#yixuan_utilities.draw_utils.o3dVisualizer.update_triangle_mesh">update_triangle_mesh</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.5</a>.</p>
</footer>
</body>
</html>
